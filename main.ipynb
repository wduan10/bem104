{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48df514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from functools import lru_cache\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9fd189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statements = pd.read_csv(\"data/annual_statements.csv\")\n",
    "df_prices = pd.read_csv(\"data/monthly_returns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ddebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statements['datadate'] = pd.to_datetime(df_statements['datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12294a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>tic</th>\n",
       "      <th>fyear</th>\n",
       "      <th>datadate</th>\n",
       "      <th>conm</th>\n",
       "      <th>revt</th>\n",
       "      <th>ni</th>\n",
       "      <th>emp</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>ceq</th>\n",
       "      <th>oancf</th>\n",
       "      <th>at</th>\n",
       "      <th>dltt</th>\n",
       "      <th>act</th>\n",
       "      <th>lct</th>\n",
       "      <th>csho</th>\n",
       "      <th>cogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2003-05-31</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>606.337</td>\n",
       "      <td>-12.410</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>294.988</td>\n",
       "      <td>34.733</td>\n",
       "      <td>686.621</td>\n",
       "      <td>164.658</td>\n",
       "      <td>396.412</td>\n",
       "      <td>203.575</td>\n",
       "      <td>31.851</td>\n",
       "      <td>496.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2004-05-31</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>651.958</td>\n",
       "      <td>3.504</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.58</td>\n",
       "      <td>301.684</td>\n",
       "      <td>14.572</td>\n",
       "      <td>709.292</td>\n",
       "      <td>248.666</td>\n",
       "      <td>432.204</td>\n",
       "      <td>131.261</td>\n",
       "      <td>32.245</td>\n",
       "      <td>523.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>747.848</td>\n",
       "      <td>15.453</td>\n",
       "      <td>2.6</td>\n",
       "      <td>16.04</td>\n",
       "      <td>314.744</td>\n",
       "      <td>50.938</td>\n",
       "      <td>732.230</td>\n",
       "      <td>227.159</td>\n",
       "      <td>474.542</td>\n",
       "      <td>160.025</td>\n",
       "      <td>32.586</td>\n",
       "      <td>598.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>897.284</td>\n",
       "      <td>35.163</td>\n",
       "      <td>3.3</td>\n",
       "      <td>24.08</td>\n",
       "      <td>422.717</td>\n",
       "      <td>-40.482</td>\n",
       "      <td>978.819</td>\n",
       "      <td>318.576</td>\n",
       "      <td>624.454</td>\n",
       "      <td>187.788</td>\n",
       "      <td>36.654</td>\n",
       "      <td>704.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>1061.169</td>\n",
       "      <td>58.660</td>\n",
       "      <td>3.9</td>\n",
       "      <td>32.50</td>\n",
       "      <td>494.243</td>\n",
       "      <td>-21.239</td>\n",
       "      <td>1067.633</td>\n",
       "      <td>253.611</td>\n",
       "      <td>645.721</td>\n",
       "      <td>256.506</td>\n",
       "      <td>37.729</td>\n",
       "      <td>837.171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gvkey  tic   fyear   datadate      conm      revt      ni  emp  \\\n",
       "0           0   1004  AIR  2002.0 2003-05-31  AAR CORP   606.337 -12.410  2.1   \n",
       "1           1   1004  AIR  2003.0 2004-05-31  AAR CORP   651.958   3.504  2.3   \n",
       "2           2   1004  AIR  2004.0 2005-05-31  AAR CORP   747.848  15.453  2.6   \n",
       "3           3   1004  AIR  2005.0 2006-05-31  AAR CORP   897.284  35.163  3.3   \n",
       "4           4   1004  AIR  2006.0 2007-05-31  AAR CORP  1061.169  58.660  3.9   \n",
       "\n",
       "   prcc_f      ceq   oancf        at     dltt      act      lct    csho  \\\n",
       "0    4.50  294.988  34.733   686.621  164.658  396.412  203.575  31.851   \n",
       "1    9.58  301.684  14.572   709.292  248.666  432.204  131.261  32.245   \n",
       "2   16.04  314.744  50.938   732.230  227.159  474.542  160.025  32.586   \n",
       "3   24.08  422.717 -40.482   978.819  318.576  624.454  187.788  36.654   \n",
       "4   32.50  494.243 -21.239  1067.633  253.611  645.721  256.506  37.729   \n",
       "\n",
       "      cogs  \n",
       "0  496.747  \n",
       "1  523.302  \n",
       "2  598.172  \n",
       "3  704.081  \n",
       "4  837.171  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_statements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92271237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AIR</th>\n",
       "      <th>ADCT.1</th>\n",
       "      <th>AAL</th>\n",
       "      <th>ASA</th>\n",
       "      <th>PNW</th>\n",
       "      <th>PRG</th>\n",
       "      <th>ABT</th>\n",
       "      <th>SERV.1</th>\n",
       "      <th>WDDD</th>\n",
       "      <th>...</th>\n",
       "      <th>APG</th>\n",
       "      <th>NVT</th>\n",
       "      <th>CSTPF</th>\n",
       "      <th>ACA</th>\n",
       "      <th>CTRM</th>\n",
       "      <th>BBUS</th>\n",
       "      <th>IMUX</th>\n",
       "      <th>ARMP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>HYFM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02</td>\n",
       "      <td>-0.065126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.094070</td>\n",
       "      <td>-0.006187</td>\n",
       "      <td>-0.085308</td>\n",
       "      <td>-0.060030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-03</td>\n",
       "      <td>-0.150562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.037873</td>\n",
       "      <td>0.088408</td>\n",
       "      <td>0.044042</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-04</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>0.080297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05</td>\n",
       "      <td>0.159794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.154016</td>\n",
       "      <td>0.026004</td>\n",
       "      <td>0.103219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4730 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0       AIR  ADCT.1  AAL       ASA       PNW       PRG       ABT  \\\n",
       "0    2003-01       NaN     NaN  NaN       NaN       NaN       NaN       NaN   \n",
       "1    2003-02 -0.065126     NaN  NaN -0.094070 -0.006187 -0.085308 -0.060030   \n",
       "2    2003-03 -0.150562     NaN  NaN -0.037873  0.088408  0.044042  0.055868   \n",
       "3    2003-04  0.026455     NaN  NaN  0.015850 -0.000601  0.049628  0.080297   \n",
       "4    2003-05  0.159794     NaN  NaN  0.018440  0.154016  0.026004  0.103219   \n",
       "\n",
       "   SERV.1  WDDD  ...  APG  NVT  CSTPF  ACA  CTRM  BBUS  IMUX      ARMP  SNOW  \\\n",
       "0     NaN   NaN  ...  NaN  NaN    NaN  NaN   NaN   NaN   NaN       NaN   NaN   \n",
       "1     NaN   0.0  ...  NaN  NaN    NaN  NaN   NaN   NaN   NaN  0.000000   NaN   \n",
       "2     NaN   0.0  ...  NaN  NaN    NaN  NaN   NaN   NaN   NaN  0.586207   NaN   \n",
       "3     NaN   0.0  ...  NaN  NaN    NaN  NaN   NaN   NaN   NaN  0.586957   NaN   \n",
       "4     NaN   0.0  ...  NaN  NaN    NaN  NaN   NaN   NaN   NaN  0.643836   NaN   \n",
       "\n",
       "   HYFM  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   NaN  \n",
       "\n",
       "[5 rows x 4730 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2be00419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decile_memberships(df_statements: pd.DataFrame,\n",
    "                             id_col: str = 'tic',\n",
    "                             n_bins: int = 10):\n",
    "    \"\"\"Return nested dict: deciles_by_year[year][decile] -> list of tickers.\"\"\"\n",
    "    df = df_statements.copy()\n",
    "\n",
    "    # --- Basic sanity ---\n",
    "    # Ensure expected columns exist\n",
    "    req = {'gvkey','tic','fyear','datadate','revt','ni','oancf','ceq','prcc_f','csho'}\n",
    "    missing = req - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"df_statements missing columns: {missing}\")\n",
    "\n",
    "    # Parse date + sort\n",
    "    # make sure dates are sorted within gvkey\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    df = df.sort_values(['gvkey','datadate']).reset_index(drop=True)\n",
    "\n",
    "    # --- Market equity & core ratios (at fiscal-year end) ---\n",
    "    df['ME'] = df['prcc_f'] * df['csho']   # assumes price $/share and shares in millions\n",
    "    # Guard against divide-by-zero or negative ME\n",
    "    df.loc[~(df['ME'] > 0), 'ME'] = np.nan\n",
    "\n",
    "    df['bm'] = df['ceq']   / df['ME']              # Book-to-Market\n",
    "    df['ep'] = df['ni']    / df['ME']              # Earnings-to-Price\n",
    "    df['cp'] = df['oancf'] / df['ME']              # CashFlow-to-Price\n",
    "\n",
    "    # --- GS: pre-formation 5y average sales growth ---\n",
    "    # First compute YoY growth in revenue per firm\n",
    "    df['revt_lag'] = df.groupby('gvkey')['revt'].shift(1)\n",
    "    df['sales_growth'] = (df['revt'] / df['revt_lag']) - 1.0\n",
    "    # Pre-formation average over *prior* 5 years (exclude current fyear reading)\n",
    "    gs = (df.groupby('gvkey')['sales_growth']\n",
    "        .apply(lambda s: s.shift(1).rolling(5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True))   # <- key: drop the gvkey level\n",
    "\n",
    "    df['gs'] = gs\n",
    "\n",
    "    # --- Formation year (end of April Y uses fyear=Y-1 financials) ---\n",
    "    df['formation_year'] = df['fyear'].astype('Int64') + 1\n",
    "\n",
    "    # Keep the columns we need\n",
    "    chars = df[['formation_year','gvkey','tic','bm','ep','cp','gs','ME']].dropna(subset=['formation_year'])\n",
    "\n",
    "    # Helper to form deciles for one characteristic\n",
    "    def one_char_deciles(chars_df: pd.DataFrame, char: str):\n",
    "        cs = chars_df[['formation_year','gvkey','tic',char,'ME']].dropna(subset=[char]).copy()\n",
    "\n",
    "        out_rows = []\n",
    "        for Y, g in cs.groupby('formation_year'):\n",
    "            # Need enough names to form deciles\n",
    "            if g[char].nunique() < n_bins:\n",
    "                continue\n",
    "            # qcut on rank to avoid duplicate-bin issues\n",
    "            g = g.copy()\n",
    "            rk = g[char].rank(method='first')\n",
    "            try:\n",
    "                g['decile'] = pd.qcut(rk, n_bins, labels=False) + 1  # 1..10\n",
    "            except ValueError:\n",
    "                # fallback: skip if still not enough spread\n",
    "                continue\n",
    "\n",
    "            # Collect members per decile\n",
    "            members = (g.groupby('decile')[id_col]\n",
    "                         .apply(list)\n",
    "                         .reindex(range(1, n_bins+1), fill_value=[])\n",
    "                         .to_dict())\n",
    "            out_rows.append((Y, members))\n",
    "\n",
    "        # Build nested dict: deciles_by_year[year][decile] -> list\n",
    "        deciles_by_year = {}\n",
    "        for Y, members in out_rows:\n",
    "            deciles_by_year[int(Y)] = {int(k): v for k, v in members.items()}\n",
    "        return deciles_by_year\n",
    "\n",
    "    return {\n",
    "        'bm' : one_char_deciles(chars, 'bm'),\n",
    "        'ep' : one_char_deciles(chars, 'ep'),\n",
    "        'cp' : one_char_deciles(chars, 'cp'),\n",
    "        'gs' : one_char_deciles(chars, 'gs'),\n",
    "    }\n",
    "    \n",
    "deciles_by_year = build_decile_memberships(df_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ffa04e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL', 'WDDD', 'PBAJ', 'ANDR', 'BA']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: show a couple stocks in the first decile in year 2020\n",
    "# here, lower decile = low B/M ratio = glamour stock\n",
    "deciles_by_year['bm'][2020][1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d21f4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_period_m(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure monthly PeriodIndex; tolerate string or Timestamp index.\"\"\"\n",
    "    if isinstance(df.index, pd.PeriodIndex) and df.index.freqstr == \"M\":\n",
    "        return df\n",
    "    try:\n",
    "        idx = pd.PeriodIndex(df.index, freq=\"M\")\n",
    "    except Exception:\n",
    "        idx = pd.to_datetime(df.index).to_period(\"M\")\n",
    "    out = df.copy()\n",
    "    out.index = idx\n",
    "    return out\n",
    "\n",
    "def _compound_12m(window: pd.Series) -> float:\n",
    "    \"\"\"Compound 12 monthly decimal returns; require all 12 finite values.\"\"\"\n",
    "    if window.shape[0] != 12:\n",
    "        return np.nan\n",
    "    w = window.astype(float)\n",
    "    if not np.isfinite(w).all():\n",
    "        return np.nan\n",
    "    return float((1.0 + w).prod() - 1.0)\n",
    "\n",
    "def _nanmean_rowwise(arr: np.ndarray, axis=0):\n",
    "    \"\"\"nanmean without warnings: NaN if all-NaN.\"\"\"\n",
    "    if arr.size == 0:\n",
    "        return np.full((arr.shape[1-axis],), np.nan, dtype=float)\n",
    "    counts = np.sum(~np.isnan(arr), axis=axis, dtype=float)\n",
    "    sums = np.nansum(arr, axis=axis)\n",
    "    out = np.divide(sums, counts, out=np.full_like(sums, np.nan, dtype=float), where=counts>0)\n",
    "    return out\n",
    "\n",
    "def _nanprod1p_over_row(row: np.ndarray) -> float:\n",
    "    \"\"\"Compound across (1+r) ignoring NaNs; NaN if none.\"\"\"\n",
    "    valid = row[np.isfinite(row)]\n",
    "    if valid.size == 0:\n",
    "        return np.nan\n",
    "    return float(np.prod(1.0 + valid) - 1.0)\n",
    "\n",
    "# --- core: post-formation using df_prices monthly RETURNS (decimal) ---\n",
    "\n",
    "def postformation_returns_5y_from_df(df_prices: pd.DataFrame,\n",
    "                                     ticker: str,\n",
    "                                     formation_year: int) -> list[float]:\n",
    "    \"\"\"\n",
    "    df_prices: monthly RETURNS (decimal), index monthly, cols tickers.\n",
    "    R_k windows: May(Y+k-1)..Apr(Y+k).\n",
    "    \"\"\"\n",
    "    if ticker not in df_prices.columns:\n",
    "        return [np.nan]*5\n",
    "\n",
    "    s = _as_period_m(df_prices)[ticker]\n",
    "\n",
    "    out = []\n",
    "    for k in range(5):\n",
    "        y_start = formation_year + k\n",
    "        p0 = pd.Period(f\"{y_start}-05\", freq=\"M\")\n",
    "        months = [p0 + i for i in range(12)]\n",
    "        try:\n",
    "            window = s.loc[months]\n",
    "        except KeyError:\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        out.append(_compound_12m(window))\n",
    "    return out\n",
    "\n",
    "# --- cached wrapper bound to df_prices ---\n",
    "\n",
    "def make_pf5y_cached(df_prices: pd.DataFrame):\n",
    "    dfp = _as_period_m(df_prices)\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def _pf5y_cached(ticker: str, formation_year: int):\n",
    "        try:\n",
    "            vals = postformation_returns_5y_from_df(dfp, ticker, formation_year)\n",
    "            if vals is None or len(vals) != 5:\n",
    "                return (np.nan,)*5\n",
    "            return tuple(float(x) if x is not None else np.nan for x in vals)\n",
    "        except Exception:\n",
    "            return (np.nan,)*5\n",
    "    _pf5y_cached.cache_clear()\n",
    "\n",
    "    return _pf5y_cached\n",
    "\n",
    "# --- cohort & panel ---\n",
    "\n",
    "def _cohort_equal_weight_R1toR5(tickers, formation_year, _pf5y_cached_fn):\n",
    "    if not tickers:\n",
    "        return [np.nan]*5\n",
    "    rets = np.array([_pf5y_cached_fn(t, formation_year) for t in tickers], dtype=float)  # [N x 5]\n",
    "    out = _nanmean_rowwise(rets, axis=0)  # -> [5], NaN if cohort has no valid data\n",
    "    return out.tolist()\n",
    "\n",
    "def build_panel_for_char(deciles_by_year, df_prices, char_key='bm', deciles=10, years=None):\n",
    "    by_year = deciles_by_year[char_key]\n",
    "    Ys_all = sorted(by_year.keys())\n",
    "    years = Ys_all if years is None else [y for y in years if y in by_year]\n",
    "\n",
    "    _pf5y_cached_fn = make_pf5y_cached(df_prices)\n",
    "\n",
    "    sum_R = np.zeros((5, deciles), dtype=float)\n",
    "    cnt_R = np.zeros((5, deciles), dtype=float)\n",
    "\n",
    "    for Y in years:\n",
    "        for d in range(1, deciles+1):\n",
    "            tickers = by_year.get(Y, {}).get(d, [])\n",
    "            r1to5 = np.array(_cohort_equal_weight_R1toR5(tickers, Y, _pf5y_cached_fn), dtype=float)\n",
    "            mask = np.isfinite(r1to5)\n",
    "            sum_R[mask, d-1] += r1to5[mask]\n",
    "            cnt_R[mask, d-1] += 1.0\n",
    "\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        panel = sum_R / np.where(cnt_R==0.0, np.nan, cnt_R)\n",
    "\n",
    "    panel_df = pd.DataFrame(panel,\n",
    "                            index=[f\"R{i}\" for i in range(1,6)],\n",
    "                            columns=[str(d) for d in range(1, deciles+1)])\n",
    "\n",
    "    ar = pd.Series(_nanmean_rowwise(panel, axis=0), index=panel_df.columns, name=\"AR\")\n",
    "    cr5 = pd.Series([_nanprod1p_over_row(panel[:, j]) for j in range(panel.shape[1])],\n",
    "                    index=panel_df.columns, name=\"CR_5y\")\n",
    "\n",
    "    return panel_df, ar, cr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c3d02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3         4         5         6         7  \\\n",
      "R1  0.230864  0.165150  0.154330  0.130206  0.152722  0.189832  0.141165   \n",
      "R2  0.122684  0.109656  0.125627  0.149815  0.116547  0.110811  0.117326   \n",
      "R3  0.120758  0.112367  0.149921  0.117748  0.121103  0.116944  0.125622   \n",
      "R4  0.085786  0.111583  0.101683  0.110637  0.099287  0.108779  0.114245   \n",
      "R5  0.119981  0.132974  0.113424  0.097341  0.110731  0.127159  0.110761   \n",
      "\n",
      "           8         9        10  \n",
      "R1  0.172715  0.202299  0.284169  \n",
      "R2  0.132551  0.131110  0.214504  \n",
      "R3  0.114867  0.147945  0.186675  \n",
      "R4  0.133613  0.148052  0.163335  \n",
      "R5  0.093090  0.127691  0.171839  \n",
      "1     0.136015\n",
      "2     0.126346\n",
      "3     0.128997\n",
      "4     0.121149\n",
      "5     0.120078\n",
      "6     0.130705\n",
      "7     0.121824\n",
      "8     0.129367\n",
      "9     0.151419\n",
      "10    0.204105\n",
      "Name: AR, dtype: float64\n",
      "1     0.883364\n",
      "2     0.811259\n",
      "3     0.832777\n",
      "4     0.770284\n",
      "5     0.761842\n",
      "6     0.844962\n",
      "7     0.776324\n",
      "8     0.834823\n",
      "9     1.021109\n",
      "10    1.523051\n",
      "Name: CR_5y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the monthly returns you already built\n",
    "df_prices = pd.read_csv(\"data/monthly_returns4.csv\", index_col=0)\n",
    "\n",
    "# Build panel for, say, book-to-market deciles\n",
    "panel_df, ar, cr5 = build_panel_for_char(deciles_by_year, df_prices, char_key='bm', deciles=10)\n",
    "\n",
    "print(panel_df)  # rows R1..R5 by decile\n",
    "print(ar)        # average annual return across R1..R5 per decile\n",
    "print(cr5)       # 5-year compounded return per decile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e87ee2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3         4         5         6         7  \\\n",
      "R1  0.227251  0.173466  0.160419  0.157552  0.139625  0.162757  0.146482   \n",
      "R2  0.178292  0.085334  0.064805  0.136292  0.126109  0.128571  0.117178   \n",
      "R3  0.111257  0.115339  0.051022  0.144934  0.123267  0.110023  0.136120   \n",
      "R4  0.074448  0.080854  0.097834  0.100324  0.093644  0.101602  0.118173   \n",
      "R5  0.117135  0.163243  0.107877  0.119048  0.107860  0.112476  0.127549   \n",
      "\n",
      "           8         9        10  \n",
      "R1  0.173720  0.181839  0.291467  \n",
      "R2  0.131451  0.151315  0.207648  \n",
      "R3  0.135601  0.137397  0.208813  \n",
      "R4  0.124371  0.134966  0.216348  \n",
      "R5  0.114344  0.108298  0.132491  \n",
      "1     0.141677\n",
      "2     0.123647\n",
      "3     0.096391\n",
      "4     0.131630\n",
      "5     0.118101\n",
      "6     0.123086\n",
      "7     0.129100\n",
      "8     0.135897\n",
      "9     0.142763\n",
      "10    0.211353\n",
      "Name: AR, dtype: float64\n",
      "1     0.928822\n",
      "2     0.785988\n",
      "3     0.579520\n",
      "4     0.854301\n",
      "5     0.746572\n",
      "6     0.785112\n",
      "7     0.834671\n",
      "8     0.889535\n",
      "9     0.946724\n",
      "10    1.597021\n",
      "Name: CR_5y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the monthly returns you already built\n",
    "df_prices = pd.read_csv(\"data/monthly_returns4.csv\", index_col=0)\n",
    "\n",
    "# Build panel for, say, book-to-market deciles\n",
    "panel_df, ar, cr5 = build_panel_for_char(deciles_by_year, df_prices, char_key='cp', deciles=10)\n",
    "\n",
    "print(panel_df)  # rows R1..R5 by decile\n",
    "print(ar)        # average annual return across R1..R5 per decile\n",
    "print(cr5)       # 5-year compounded return per decile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "256638ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3         4         5         6         7  \\\n",
      "R1  0.218511  0.259526  0.219327  0.186359  0.162162  0.141284  0.138132   \n",
      "R2  0.175050  0.149930  0.129714  0.152518  0.104449  0.108621  0.128862   \n",
      "R3  0.178587  0.099141  0.124906  0.089504  0.137267  0.133705  0.134732   \n",
      "R4  0.197867  0.096823  0.143069  0.111286  0.108970  0.099451  0.107490   \n",
      "R5  0.146087  0.097596  0.164189  0.114651  0.134431  0.109840  0.107333   \n",
      "\n",
      "           8         9        10  \n",
      "R1  0.160866  0.151648  0.208449  \n",
      "R2  0.135093  0.138354  0.144691  \n",
      "R3  0.120605  0.125472  0.174058  \n",
      "R4  0.102602  0.132027  0.136950  \n",
      "R5  0.111579  0.105218  0.123138  \n",
      "1     0.183220\n",
      "2     0.140603\n",
      "3     0.156241\n",
      "4     0.130864\n",
      "5     0.129456\n",
      "6     0.118580\n",
      "7     0.123310\n",
      "8     0.126149\n",
      "9     0.130544\n",
      "10    0.157457\n",
      "Name: AR, dtype: float64\n",
      "1     1.316720\n",
      "2     0.916511\n",
      "3     1.062056\n",
      "4     0.845260\n",
      "5     0.836424\n",
      "6     0.750302\n",
      "7     0.787907\n",
      "8     0.809778\n",
      "9     0.846019\n",
      "10    1.073866\n",
      "Name: CR_5y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the monthly returns you already built\n",
    "df_prices = pd.read_csv(\"data/monthly_returns4.csv\", index_col=0)\n",
    "\n",
    "# Build panel for, say, book-to-market deciles\n",
    "panel_df, ar, cr5 = build_panel_for_char(deciles_by_year, df_prices, char_key='ep', deciles=10)\n",
    "\n",
    "print(panel_df)  # rows R1..R5 by decile\n",
    "print(ar)        # average annual return across R1..R5 per decile\n",
    "print(cr5)       # 5-year compounded return per decile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1845b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n",
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gvkey     tic        gs  formation_year\n",
      "0   1004     AIR  0.575769            2006\n",
      "1   1072     AVX  0.384977            2006\n",
      "2   1082  SERV.1  0.054370            2006\n",
      "3   1111  ATVI.1  0.547543            2006\n",
      "4   1173   AIM.1  0.478552            2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/chgk8nwx2wn005yx81lw4xl80000gn/T/ipykernel_93162/389755030.py:59: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "def compute_weighted_sales_growth(df_statements: pd.DataFrame, min_obs=3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lakonishok–Shleifer–Vishny (1994) GS: recency-weighted (5..1) average of\n",
    "    within-year ranks of past 5Y sales growth (Y-1..Y-5), per formation year.\n",
    "    Returns: columns ['gvkey','tic','gs','formation_year'].\n",
    "    Firms must have >= min_obs valid past-year growth observations.\n",
    "    \"\"\"\n",
    "    df = df_statements.copy()\n",
    "\n",
    "    # Ensure needed cols and types\n",
    "    for col in ['gvkey','tic','fyear','revt']:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing column '{col}'\")\n",
    "    df = df.sort_values(['gvkey','fyear']).copy()\n",
    "    df['fyear'] = pd.to_numeric(df['fyear'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Sales growth per firm-year\n",
    "    df['revt_lag'] = df.groupby('gvkey', group_keys=False)['revt'].shift(1)\n",
    "    df['sales_growth'] = (df['revt'] / df['revt_lag']) - 1.0\n",
    "\n",
    "    # Formation year = fyear + 1\n",
    "    df['formation_year'] = df['fyear'] + 1\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for Y in np.sort(df['formation_year'].dropna().unique().astype(int)):\n",
    "        # Past five fiscal years: Y-1..Y-5\n",
    "        window_years = [Y - k for k in range(1, 6)]\n",
    "        g = df.loc[df['fyear'].isin(window_years), ['gvkey','tic','fyear','sales_growth']].dropna()\n",
    "\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        # Rank within each fiscal year; higher growth => higher rank\n",
    "        g = g.copy()\n",
    "        g['rank'] = g.groupby('fyear', group_keys=False)['sales_growth'].rank(method='average')\n",
    "        # Normalize ranks to 0..1 per year to handle different cross-section sizes\n",
    "        max_rank = g.groupby('fyear', group_keys=False)['rank'].transform('max')\n",
    "        g['rank_pct'] = np.where(max_rank > 0, g['rank'] / max_rank, np.nan)\n",
    "\n",
    "        # Recency weights: Y-1->5, Y-2->4, ..., Y-5->1\n",
    "        w = 6 - (Y - g['fyear'])\n",
    "        g['weight'] = w.astype(float)\n",
    "        g = g.loc[g['weight'].between(1, 5)]\n",
    "\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        # Keep firms with at least min_obs valid past-year growths\n",
    "        g_valid = (g.groupby(['gvkey','tic'], group_keys=False)\n",
    "                     .filter(lambda grp: grp['sales_growth'].notnull().sum() >= min_obs))\n",
    "\n",
    "        if g_valid.empty:\n",
    "            continue\n",
    "\n",
    "        # Weighted average of rank_pct using 'weight' per firm\n",
    "        # Return a 1-row Series so .reset_index() works reliably\n",
    "        gs = (g_valid.groupby(['gvkey','tic'])\n",
    "                      .apply(lambda x: pd.Series({\n",
    "                          'gs': np.average(x['rank_pct'].to_numpy(),\n",
    "                                           weights=x['weight'].to_numpy())\n",
    "                      }))\n",
    "                      .reset_index())\n",
    "\n",
    "        gs['formation_year'] = Y\n",
    "        rows.append(gs)\n",
    "\n",
    "    if not rows:\n",
    "        # No valid GS for any formation year\n",
    "        return pd.DataFrame(columns=['gvkey','tic','gs','formation_year'])\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "gs_table = compute_weighted_sales_growth(df_statements)\n",
    "print(gs_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb463c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decile_memberships_with_gs(df_statements: pd.DataFrame,\n",
    "                                     gs_table: pd.DataFrame,\n",
    "                                     id_col: str = 'tic',\n",
    "                                     n_bins: int = 10):\n",
    "    \"\"\"\n",
    "    Return nested dict: deciles_by_year[char_key][year][decile] -> list of tickers.\n",
    "    Uses precomputed gs_table with columns ['gvkey','tic','gs','formation_year'].\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_statements.copy()\n",
    "\n",
    "    # --- Basic sanity ---\n",
    "    req = {'gvkey','tic','fyear','datadate','ni','oancf','ceq','prcc_f','csho'}\n",
    "    missing = req - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"df_statements missing columns: {missing}\")\n",
    "\n",
    "    # --- Clean & sort ---\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    df = df.sort_values(['gvkey','datadate']).reset_index(drop=True)\n",
    "\n",
    "    # --- Market equity & core ratios (at fiscal-year end) ---\n",
    "    df['ME'] = df['prcc_f'] * df['csho']     # assumes shares in millions, price in $\n",
    "    df.loc[~(df['ME'] > 0), 'ME'] = np.nan\n",
    "\n",
    "    df['bm'] = df['ceq']   / df['ME']        # Book-to-Market\n",
    "    df['ep'] = df['ni']    / df['ME']        # Earnings-to-Price\n",
    "    df['cp'] = df['oancf'] / df['ME']        # CashFlow-to-Price\n",
    "\n",
    "    # --- Formation year (end of April Y uses fyear=Y-1 financials) ---\n",
    "    df['formation_year'] = pd.to_numeric(df['fyear'], errors='coerce').astype('Int64') + 1\n",
    "\n",
    "    # --- Merge precomputed GS ---\n",
    "    # Ensure types align; drop dup rows in gs_table if any\n",
    "    gs = gs_table.copy()\n",
    "    if 'formation_year' in gs.columns:\n",
    "        gs['formation_year'] = pd.to_numeric(gs['formation_year'], errors='coerce').astype('Int64')\n",
    "    gs = (gs\n",
    "          .dropna(subset=['gvkey','tic','formation_year'])\n",
    "          .drop_duplicates(subset=['gvkey','tic','formation_year'], keep='last'))\n",
    "    # Expect columns: gvkey, tic, gs, formation_year\n",
    "    if not {'gvkey','tic','gs','formation_year'}.issubset(gs.columns):\n",
    "        raise ValueError(\"gs_table must have columns: ['gvkey','tic','gs','formation_year']\")\n",
    "\n",
    "    df = df.merge(gs[['gvkey','tic','formation_year','gs']],\n",
    "                  on=['gvkey','tic','formation_year'], how='left')\n",
    "\n",
    "    # Keep only necessary columns for decile formation\n",
    "    chars = df[['formation_year','gvkey','tic','bm','ep','cp','gs','ME']].dropna(subset=['formation_year'])\n",
    "\n",
    "    def one_char_deciles(chars_df: pd.DataFrame, char: str):\n",
    "        # Use available firms with non-null characteristic\n",
    "        cs = chars_df[['formation_year','gvkey','tic',char,'ME']].dropna(subset=[char]).copy()\n",
    "\n",
    "        out_rows = []\n",
    "        for Y, g in cs.groupby('formation_year', sort=True):\n",
    "            # Need enough distinct values to form bins\n",
    "            if g[char].nunique(dropna=True) < n_bins:\n",
    "                continue\n",
    "\n",
    "            g = g.copy()\n",
    "            # Rank before qcut to avoid duplicate-edge errors\n",
    "            rk = g[char].rank(method='first')\n",
    "            try:\n",
    "                g['decile'] = pd.qcut(rk, n_bins, labels=False) + 1  # 1..n_bins\n",
    "            except ValueError:\n",
    "                # still not enough spread\n",
    "                continue\n",
    "\n",
    "            members = (g.groupby('decile', sort=True)[id_col]\n",
    "                         .apply(list)\n",
    "                         .reindex(range(1, n_bins+1), fill_value=[])\n",
    "                         .to_dict())\n",
    "            out_rows.append((int(Y), members))\n",
    "\n",
    "        # Build nested dict: deciles_by_year[year][decile] -> list\n",
    "        deciles_by_year = {}\n",
    "        for Y, members in out_rows:\n",
    "            deciles_by_year[Y] = {int(k): v for k, v in members.items()}\n",
    "        return deciles_by_year\n",
    "\n",
    "    return {\n",
    "        'bm': one_char_deciles(chars, 'bm'),\n",
    "        'ep': one_char_deciles(chars, 'ep'),\n",
    "        'cp': one_char_deciles(chars, 'cp'),\n",
    "        'gs': one_char_deciles(chars, 'gs'),  # uses merged gs from gs_table\n",
    "    }\n",
    "\n",
    "# note that decile 1 is value for gs, but glamour for other ratios\n",
    "deciles_by_year2 = build_decile_memberships_with_gs(df_statements, gs_table, id_col='tic', n_bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a678dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3         4         5         6         7  \\\n",
      "R1  0.183009  0.146046  0.124904  0.160756  0.123126  0.143935  0.115408   \n",
      "R2  0.123007  0.120306  0.144018  0.117842  0.101011  0.125919  0.124240   \n",
      "R3  0.140216  0.139340  0.149814  0.139186  0.137195  0.169998  0.134152   \n",
      "R4  0.172035  0.187767  0.131890  0.141335  0.130330  0.178253  0.156298   \n",
      "R5  0.157961  0.126892  0.168525  0.119723  0.182910  0.119861  0.109558   \n",
      "\n",
      "           8         9        10  \n",
      "R1  0.116074  0.096647  0.082407  \n",
      "R2  0.153553  0.119221  0.105054  \n",
      "R3  0.141844  0.110344  0.111434  \n",
      "R4  0.152605  0.236290  0.147169  \n",
      "R5  0.129683  0.166986  0.127041  \n",
      "1     0.155246\n",
      "2     0.144070\n",
      "3     0.143830\n",
      "4     0.135768\n",
      "5     0.134914\n",
      "6     0.147593\n",
      "7     0.127931\n",
      "8     0.138752\n",
      "9     0.145898\n",
      "10    0.114621\n",
      "Name: AR, dtype: float64\n",
      "1     1.055854\n",
      "2     0.957968\n",
      "3     0.957125\n",
      "4     0.889032\n",
      "5     0.880234\n",
      "6     0.988367\n",
      "7     0.824667\n",
      "8     0.914144\n",
      "9     0.966195\n",
      "10    0.718798\n",
      "Name: CR_5y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the monthly returns you already built\n",
    "df_prices = pd.read_csv(\"data/monthly_returns4.csv\", index_col=0)\n",
    "\n",
    "# Build panel for, say, book-to-market deciles\n",
    "panel_df, ar, cr5 = build_panel_for_char(deciles_by_year2, df_prices, char_key='gs', deciles=10)\n",
    "\n",
    "print(panel_df)  # rows R1..R5 by decile\n",
    "print(ar)        # average annual return across R1..R5 per decile\n",
    "print(cr5)       # 5-year compounded return per decile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f72274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
